loans = read.csv("loans.csv")
str(loans)
summary(loans)
table(loans$not.fully.paid )
1533/(1533+8045)

missing = subset(loans, is.na(log.annual.inc) | is.na(days.with.cr.line) | is.na(revol.util) | is.na(inq.last.6mths) 
| is.na(delinq.2yrs) | is.na(pub.rec))
str(missing)

We see that only 62 of 9578 loans have missing data; removing this small number of observations would not lead to 
overfitting. From table(missing$not.fully.paid), we see that 12 of 62 loans with missing data were not fully paid, or 
19.35%. This rate is similar to the 16.01% across all loans, so the form of biasing described is not an issue. 
However, to predict risk for loans with missing data we need to fill in the missing values instead of removing the 
observations.

install.packages("mice")



loansi = read.csv("loans_imputed.csv")
set.seed(144)
install.packages("caTools")
library(caTools)
spl = sample.split(loansi$not.fully.paid, 0.7)
train = subset(loans, spl == TRUE)
test = subset(loans, spl == FALSE)
loanlog = glm(not.fully.paid~., data = train, family= binomial)
summary(loanlog)
-700*(.00887)+710*(.00887)

loanpred = predict(loanlog, newdata= test, type = "response")
str(loanpred)
test$predicted.risk = loanpred 
table(test$not.fully.paid, loanpred>0.5)
(2387+3)/(2387+3+12+455)
table(test$not.fully.paid)

2413/(2413+460)
